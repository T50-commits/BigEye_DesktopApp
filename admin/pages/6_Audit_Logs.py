"""
BigEye Pro Admin ‚Äî ‡∏´‡∏ô‡πâ‡∏≤‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏£‡∏∞‡∏ö‡∏ö (Audit Logs)
‡∏Å‡∏£‡∏≠‡∏á‡∏ï‡∏≤‡∏°‡∏£‡∏∞‡∏î‡∏±‡∏ö, ‡∏î‡∏π‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î JSON
"""
import streamlit as st
import json
from datetime import datetime, timedelta, timezone
from google.cloud.firestore_v1 import FieldFilter

from utils.firestore_client import audit_logs_ref, users_ref


st.header("üìã ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏£‡∏∞‡∏ö‡∏ö")


# ‚îÄ‚îÄ Data loading ‚îÄ‚îÄ

def load_logs(severity_filter: str = "ALL", days: int = 7, limit: int = 200) -> list[dict]:
    results = []
    try:
        ref = audit_logs_ref()

        if severity_filter == "WARNING+":
            for sev in ["WARNING", "ERROR", "CRITICAL"]:
                docs = list(
                    ref.where(filter=FieldFilter("severity", "==", sev))
                    .limit(limit)
                    .stream()
                )
                for doc in docs:
                    d = doc.to_dict()
                    d["id"] = doc.id
                    results.append(d)
        elif severity_filter != "ALL":
            docs = list(
                ref.where(filter=FieldFilter("severity", "==", severity_filter))
                .limit(limit)
                .stream()
            )
            for doc in docs:
                d = doc.to_dict()
                d["id"] = doc.id
                results.append(d)
        else:
            docs = list(ref.limit(limit).stream())
            for doc in docs:
                d = doc.to_dict()
                d["id"] = doc.id
                results.append(d)

        # Filter by date cutoff in Python (avoid composite index)
        cutoff = datetime.now(timezone.utc) - timedelta(days=days)
        filtered = []
        for r in results:
            ts = r.get("timestamp") or r.get("created_at")
            if ts:
                if hasattr(ts, "tzinfo") and ts.tzinfo is None:
                    ts = ts.replace(tzinfo=timezone.utc)
                if ts >= cutoff:
                    filtered.append(r)
            else:
                filtered.append(r)
        results = filtered

        # Sort by timestamp/created_at descending
        def _get_ts(x):
            return x.get("timestamp") or x.get("created_at") or datetime.min.replace(tzinfo=timezone.utc)
        results.sort(key=_get_ts, reverse=True)
        results = results[:limit]

    except Exception as e:
        st.error(f"‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡πÇ‡∏´‡∏•‡∏î‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å: {e}")

    return results


def severity_color(sev: str) -> str:
    return {
        "INFO": "üîµ",
        "WARNING": "üü°",
        "ERROR": "üî¥",
        "CRITICAL": "‚ö´",
    }.get(sev, "‚ö™")


_EVENT_LABELS = {
    "USER_REGISTER": "‡∏™‡∏°‡∏±‡∏Ñ‡∏£‡∏™‡∏°‡∏≤‡∏ä‡∏¥‡∏Å‡πÉ‡∏´‡∏°‡πà",
    "LOGIN_FAILED_WRONG_PASSWORD": "‡∏•‡πá‡∏≠‡∏Å‡∏≠‡∏¥‡∏ô‡∏ú‡∏¥‡∏î‡∏£‡∏´‡∏±‡∏™",
    "LOGIN_FAILED_DEVICE_MISMATCH": "‡∏≠‡∏∏‡∏õ‡∏Å‡∏£‡∏ì‡πå‡πÑ‡∏°‡πà‡∏ï‡∏£‡∏á",
    "JOB_RESERVED": "‡∏à‡∏≠‡∏á‡∏á‡∏≤‡∏ô",
    "JOB_COMPLETED": "‡∏á‡∏≤‡∏ô‡πÄ‡∏™‡∏£‡πá‡∏à",
    "JOB_EXPIRED_AUTO_REFUND": "‡∏á‡∏≤‡∏ô‡∏´‡∏°‡∏î‡∏≠‡∏≤‡∏¢‡∏∏-‡∏Ñ‡∏∑‡∏ô‡πÄ‡∏Ñ‡∏£‡∏î‡∏¥‡∏ï",
    "TOPUP_SUCCESS": "‡πÄ‡∏ï‡∏¥‡∏°‡πÄ‡∏á‡∏¥‡∏ô‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à",
}


_email_cache: dict[str, str] = {}

def _resolve_email(user_id: str) -> str:
    if not user_id:
        return "‚Äî"
    if user_id in _email_cache:
        return _email_cache[user_id]
    try:
        doc = users_ref().document(user_id).get()
        if doc.exists:
            email = doc.to_dict().get("email", user_id[:12])
            _email_cache[user_id] = email
            return email
    except Exception:
        pass
    _email_cache[user_id] = user_id[:12]
    return user_id[:12]


# ‚îÄ‚îÄ Filters ‚îÄ‚îÄ

col1, col2, col3 = st.columns([2, 1, 1])
with col1:
    severity_filter = st.selectbox(
        "‡∏£‡∏∞‡∏î‡∏±‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡∏£‡∏∏‡∏ô‡πÅ‡∏£‡∏á",
        ["ALL", "WARNING+", "INFO", "WARNING", "ERROR", "CRITICAL"],
        index=1,
    )
with col2:
    days = st.number_input("‡∏¢‡πâ‡∏≠‡∏ô‡∏´‡∏•‡∏±‡∏á (‡∏ß‡∏±‡∏ô)", value=7, min_value=1, max_value=90, step=1)
with col3:
    st.markdown("<br>", unsafe_allow_html=True)
    if st.button("üîÑ ‡∏£‡∏µ‡πÄ‡∏ü‡∏£‡∏ä"):
        st.cache_data.clear()
        st.rerun()

logs = load_logs(severity_filter, days)

if not logs:
    st.info(f"‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å (‡∏£‡∏∞‡∏î‡∏±‡∏ö: {severity_filter}, ‡∏¢‡πâ‡∏≠‡∏ô‡∏´‡∏•‡∏±‡∏á {days} ‡∏ß‡∏±‡∏ô)")
    st.stop()

st.caption(f"‡πÅ‡∏™‡∏î‡∏á {len(logs)} ‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£")

# ‚îÄ‚îÄ Log entries ‚îÄ‚îÄ

for i, log in enumerate(logs):
    ts = log.get("timestamp") or log.get("created_at", "")
    if hasattr(ts, "strftime"):
        ts_str = ts.strftime("%Y-%m-%d %H:%M:%S")
    else:
        ts_str = str(ts)

    sev = log.get("severity", "INFO")
    event_type = log.get("event_type", log.get("event", log.get("action", "‚Äî")))
    event_label = _EVENT_LABELS.get(event_type, event_type)
    user_id = log.get("user_id", log.get("uid", ""))
    user_email = _resolve_email(user_id) if user_id else "‚Äî"
    emoji = severity_color(sev)

    details = log.get("details", {})
    detail_str = ""
    if isinstance(details, dict):
        # Show key info inline
        if "email" in details:
            detail_str = f" | {details['email']}"
        elif "job_token" in details:
            detail_str = f" | job: {details['job_token'][:8]}..."

    with st.expander(f"{emoji} `{ts_str}` ‚Äî **{event_label}** ‚Äî {user_email} ‚Äî {sev}{detail_str}"):
        # Show structured info instead of raw JSON
        st.markdown(f"**‡πÄ‡∏´‡∏ï‡∏∏‡∏Å‡∏≤‡∏£‡∏ì‡πå:** {event_type}")
        st.markdown(f"**‡∏ú‡∏π‡πâ‡πÉ‡∏ä‡πâ:** {user_email}")
        if isinstance(details, dict) and details:
            st.markdown("**‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î:**")
            detail_display = {}
            for k, v in details.items():
                if hasattr(v, "isoformat"):
                    detail_display[k] = v.isoformat()
                else:
                    detail_display[k] = v
            st.json(detail_display)
